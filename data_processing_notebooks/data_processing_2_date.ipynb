{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed9c5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:92% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "from os.path import expanduser\n",
    "## actions required!!!!!!!!!!!!!!!!!!!! change your folder path \n",
    "path = \"~/Documents/G3/MA-prediction\"\n",
    "path = expanduser(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import data_science_MA_kit as dsk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import wrds\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263019f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [yizhan]:olivershu\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "Create .pgpass file now [y/n]?: y\n",
      "Created .pgpass file successfully.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7981e33",
   "metadata": {},
   "source": [
    "# Data preprocessing 2: Date Correction\n",
    "\n",
    "Dates are very essential in corporate events, during which price volatility is extremely high. As a result, messing up event date by even only one trading day would affect return calculation to some extent. In this notebook we correct the important dates for every deal as follow:\n",
    "\n",
    "- `one_day`: the previous trading day to `dao`. Correct it to be indeed a trading day.\n",
    "- `dao`: original announcement date. Used mainly for pulling unaffected price. We don't work on correcting it now.\n",
    "- `da`: announcement date, defined by us as the next trading day after announcement. Usually this day will see the highest trading volumes. The complexity is that the official announcement on `da` provided in the database can be both on the morning or in the evening, which may affect the current or the next trading day. Thus we correct announcement date to be the one of `da` and `da`+1 trading day that has the higher trading volumes.\n",
    "- `dr`: resolution date.\n",
    "    - for completed deals, it is the effective date, defined as the first trading day after the equity's last trading day. We use the `delist_date` provided in CRSP.\n",
    "    - for withdrawn deals, it is the withdrawal date, defined as the first trading day after announcement of withdrawal. Same as `da`, we correct it to be one of `dw` and `dw` + 1 trading day with the higher trading volumes.\n",
    "\n",
    "- After correcting the dates, we create the deal duration, which is the number of trading days between `da` and `dr`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db0a78",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6c21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"{path}/data/df_merge_CRSP.h5\"\n",
    "df = pd.read_hdf(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807a267",
   "metadata": {},
   "source": [
    "# correct `one_day`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be13bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some `one_day`s in the database are not trading days\n",
    "one_day_trading_day = dsk.get_trading_day_offset(df.one_day, 0)\n",
    "# pick the indices whose one_day is not a trading day\n",
    "index = df.index[one_day_trading_day.ne(df.one_day)]\n",
    "# adjust them to the previous trading day\n",
    "df.one_day[index] = dsk.get_trading_day_offset(df.one_day[index], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2c888",
   "metadata": {},
   "source": [
    "# correct `da`\n",
    "we define `da` to be the next trading day after announcement, which should have the highest trading volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2e5e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9854/9854 [03:33<00:00, 46.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# the first trading day after `da`\n",
    "da = dsk.get_trading_day_offset(df.da, 0)\n",
    "# the second trading day after `da`\n",
    "da_plus_one_day = dsk.get_trading_day_offset(df.da, 1)\n",
    "# pull trading volume data from CRSP. take 2-4 mins\n",
    "volumes_announce = dsk.apply_func_to_ser(pd.concat([df.tpermno, da, da_plus_one_day], axis=1),\n",
    "                                dsk.get_stock_value_date_range_CRSP,\n",
    "                                'vol',\n",
    "                                return_as_df=True,\n",
    "                                columns=['day', 'day_plus_one'],\n",
    "                                db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26cd7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk.insert_cols(df, 'da', 'da_corrected', da)\n",
    "# \n",
    "index = volumes_announce.day_plus_one.gt(volumes_announce.day, fill_value=0)\n",
    "df.da_corrected[index] = da_plus_one_day[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189155f",
   "metadata": {},
   "source": [
    "# create `dr`\n",
    "- for completed deals, `dr` is the delisting date, the next trading day after last trade date\n",
    "- for withdrawn deals, `dr` is the next trading date after announcement of withdrawal, which should also have high trading volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065db70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk.insert_cols(df, 'definitive_agt', 'dr', np.nan)\n",
    "\n",
    "# for completed deals, fill date of resolution by the delisting date\n",
    "df.dr[df.statc.eq('C')] = df.delist_date[df.statc.eq('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ffbfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1895/1895 [00:29<00:00, 63.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# for withdrawn deals, fill date of resolution to one of dw and dw+1 with the higher trading volumes\n",
    "df_w = df.loc[df.statc.eq('W')]\n",
    "# \n",
    "dw = dsk.get_trading_day_offset(df_w.dw, 0)\n",
    "dw_plus_one_day = dsk.get_trading_day_offset(df_w.dw, 1)\n",
    "\n",
    "volumes_withdraw = dsk.apply_func_to_ser(pd.concat([df_w.tpermno, dw, dw_plus_one_day], axis=1),\n",
    "                                dsk.get_stock_value_date_range_CRSP,\n",
    "                                'vol',\n",
    "                                return_as_df=True,\n",
    "                                columns=['day', 'day_plus_one'],\n",
    "                                db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db48dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df.dr[df.statc.eq('W')] = dw\n",
    "# \n",
    "index = df_w.index[volumes_withdraw.day_plus_one.gt(volumes_withdraw.day, fill_value=0)]\n",
    "df.dr[index] = dw_plus_one_day[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9b067",
   "metadata": {},
   "source": [
    "# create `duration`\n",
    "Duration is the number of trading days between `da_corrected` and `dr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19dd53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk.insert_cols(df, 'definitive_agt', 'duration', dsk.trading_days_between(df.da_corrected, df.dr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a31e6f",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9bdbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/gqn1skjd0v366h5y3kbms6lh0000gn/T/ipykernel_97779/911999866.py:2: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['one_day', 'da_corrected', 'dr'], dtype='object')]\n",
      "\n",
      "  df[['one_day', 'da_corrected', 'dr', 'duration']].to_hdf(filepath, key='dates', mode='w')\n"
     ]
    }
   ],
   "source": [
    "filepath = f\"{path}/data/dates_corrected.h5\"\n",
    "df[['one_day', 'da_corrected', 'dr', 'duration']].to_hdf(filepath, key='dates', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4e209d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/gqn1skjd0v366h5y3kbms6lh0000gn/T/ipykernel_97779/2808337611.py:2: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['statc', 'one_day', 'aone_day', 'dao', 'da_corrected', 'da', 'de',\n",
      "       'dateeffexp', 'dw', 'dr', 'definitive_agt', 'da_date', 'dateval',\n",
      "       'dcom', 'dcomeff', 'last_trade_date', 'delist_date', 'att',\n",
      "       'attitude_change_yn', 'initial_rec', 'tn_CRSP', 'tn', 'ttic_CRSP',\n",
      "       'ttic', 'tcu_CRSP', 'tcu', 'texch', 'an_CRSP', 'an', 'apub',\n",
      "       'atic_CRSP', 'atic', 'acu_CRSP', 'acu', 'anatc', 'aexch', 'cross',\n",
      "       'ttf_macro_desc', 'ttf_mid_desc', 'atf_macro_desc', 'atf_mid_desc',\n",
      "       'valamend', 'consid_struct_desc', 'consid', 'consido', 'consids', 'cha',\n",
      "       'tend', 'term', 'synop', 'hdate', 'hosthprice', 'hval', 'hevent',\n",
      "       'hosthval', 'competecode', 'competeval', 'lbo', 'afinancial', 'alp',\n",
      "       'aspv', 'awk', 'hedge_fund_involv_yn', 'collar', 'lockup', 'dae',\n",
      "       'vest'],\n",
      "      dtype='object')]\n",
      "\n",
      "  df.to_hdf(filepath, key='df', mode='w')\n"
     ]
    }
   ],
   "source": [
    "filepath = f\"{path}/data/df_dates_corrected.h5\"\n",
    "df.to_hdf(filepath, key='df', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
