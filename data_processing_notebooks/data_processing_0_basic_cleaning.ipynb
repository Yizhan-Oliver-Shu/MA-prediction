{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbbeb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:92% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "from os.path import expanduser\n",
    "## actions required!!!!!!!!!!!!!!!!!!!! change your folder path \n",
    "path = \"~/Documents/G3/MA-prediction\"\n",
    "path = expanduser(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import data_science_MA_kit as dsk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "# import wrds\n",
    "import re\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb080f6a",
   "metadata": {},
   "source": [
    "# Data Processing Notebooks Outline: \n",
    "\n",
    "We download raw M&A deals data from SDC platinum, and process them in several notebooks (in order):\n",
    "- Notebook 0: basic cleaning.\n",
    "- Notebook 1 & 2: variable transformation & merge with CRSP database.\n",
    "- Notebook 3: applying filters.\n",
    "\n",
    "General guidelines for these data processing notebooks:\n",
    "- We create new columns (variables)  on all the rows first, before applying  any  filters. \n",
    "- When filtering we should not drop any row directly, in case we want to retrieve them later. Instead we add another column called `retain` to indicate whether to retain the row after applying the filters. \n",
    "- From time to time we save the intermediate result as an `hdf` file, as some codes (especially those querying the CRSP database) need tens of minutes to run. Thus we want to run it for just once and store the results. The advantage of `hdf` over `csv` is that it preserves data type like `datetime.date`. Only when we need to inspect the dataset by `Excel` or `Numbers` shall we save it as `csv`.\n",
    "- These notebooks shall be highly modular, meaning that almost every data operation should be encapsulated in a function in the helper package. Each function is developed in another individual notebook (thus tens of development notebooks). In this way the end user only needs to read the comment without digging into the codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f5bfa",
   "metadata": {},
   "source": [
    "## Data preprocessing 0: Basic Cleaning\n",
    "Specifically in this notebook we will do the following:\n",
    "\n",
    "- Load column names from the report file. Load raw data. Change column names. \n",
    "- Transform date-like columns to `datetime.date` dtype. Transform float-like columns to float.\n",
    "- Correct `consid` for some deals manually.\n",
    "- Fill missing `pr_initial` by `pr`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96ca4",
   "metadata": {},
   "source": [
    "# Load data\n",
    "## Load column names\n",
    "Load column names from the report file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2208ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['master_deal_no',\n",
       " 'statc',\n",
       " 'one_day',\n",
       " 'aone_day',\n",
       " 'dao',\n",
       " 'da',\n",
       " 'dateannorig_days',\n",
       " 'de',\n",
       " 'dateeffexp',\n",
       " 'dw',\n",
       " 'definitive_agt',\n",
       " 'da_date',\n",
       " 'dateval',\n",
       " 'dcom',\n",
       " 'dcomeff',\n",
       " 'att',\n",
       " 'attitude_change_yn',\n",
       " 'initial_rec',\n",
       " 'tn',\n",
       " 'ttic',\n",
       " 'tcu',\n",
       " 'texch',\n",
       " 'an',\n",
       " 'apub',\n",
       " 'atic',\n",
       " 'acu',\n",
       " 'anatc',\n",
       " 'aexch',\n",
       " 'cross',\n",
       " 'ttf_macro_desc',\n",
       " 'ttf_mid_desc',\n",
       " 'atf_macro_desc',\n",
       " 'atf_mid_desc',\n",
       " 'val',\n",
       " 'mv',\n",
       " 'amv',\n",
       " 'pr',\n",
       " 'pr_initial',\n",
       " 'valamend',\n",
       " 'pr4wk',\n",
       " 'pr1wk',\n",
       " 'pr1day',\n",
       " 'tprday',\n",
       " 'tpr1daya',\n",
       " 'tpr1wka',\n",
       " 'tpr4wka',\n",
       " 'ppmday',\n",
       " 'ppmwk',\n",
       " 'ppm4wk',\n",
       " 'ac4wk',\n",
       " 'ac1wk',\n",
       " 'ac1day',\n",
       " 'aprday',\n",
       " 'apr1daya',\n",
       " 'apr1wka',\n",
       " 'apr4wka',\n",
       " 'consid_struct_desc',\n",
       " 'consid',\n",
       " 'consido',\n",
       " 'consids',\n",
       " 'cha',\n",
       " 'tend',\n",
       " 'phda',\n",
       " 'psought',\n",
       " 'term',\n",
       " 'termfpct',\n",
       " 'synop',\n",
       " 'hdate',\n",
       " 'hosthprice',\n",
       " 'hval',\n",
       " 'hevent',\n",
       " 'hosthval',\n",
       " 'competecode',\n",
       " 'competeval',\n",
       " 'lbo',\n",
       " 'afinancial',\n",
       " 'alp',\n",
       " 'aspv',\n",
       " 'awk',\n",
       " 'hedge_fund_involv_yn',\n",
       " 'collar',\n",
       " 'debtrat',\n",
       " 'roe',\n",
       " 'eps',\n",
       " 'pe',\n",
       " 'pricebook',\n",
       " 'eqvalcf',\n",
       " 'eqvalsales',\n",
       " 'eqval',\n",
       " 'tlia',\n",
       " 'cass',\n",
       " 'clia',\n",
       " 'lockup',\n",
       " 'dae',\n",
       " 'vest']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = f\"{path}/data/report.rpt\"\n",
    "# extract colnames from report file\n",
    "col_names = dsk.extract_colnames_from_report_file(filepath)\n",
    "col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c68ba",
   "metadata": {},
   "source": [
    "## Load data & Change column names.\n",
    "Load data from the `csv` file. Change column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b14076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is of size (9854, 94).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statc</th>\n",
       "      <th>one_day</th>\n",
       "      <th>aone_day</th>\n",
       "      <th>dao</th>\n",
       "      <th>da</th>\n",
       "      <th>dateannorig_days</th>\n",
       "      <th>de</th>\n",
       "      <th>dateeffexp</th>\n",
       "      <th>dw</th>\n",
       "      <th>definitive_agt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricebook</th>\n",
       "      <th>eqvalcf</th>\n",
       "      <th>eqvalsales</th>\n",
       "      <th>eqval</th>\n",
       "      <th>tlia</th>\n",
       "      <th>cass</th>\n",
       "      <th>clia</th>\n",
       "      <th>lockup</th>\n",
       "      <th>dae</th>\n",
       "      <th>vest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_deal_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3846599020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/14/21</td>\n",
       "      <td>12/14/21</td>\n",
       "      <td>12/15/21</td>\n",
       "      <td>12/15/21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/31/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>6.389</td>\n",
       "      <td>16.389</td>\n",
       "      <td>4.750</td>\n",
       "      <td>5699.204</td>\n",
       "      <td>1,265.1</td>\n",
       "      <td>535.0</td>\n",
       "      <td>205.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847933020</th>\n",
       "      <td>C</td>\n",
       "      <td>12/16/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>0</td>\n",
       "      <td>05/13/22</td>\n",
       "      <td>06/30/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>5.573</td>\n",
       "      <td>59.340</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2456.130</td>\n",
       "      <td>347.3</td>\n",
       "      <td>237.8</td>\n",
       "      <td>147.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848920020</th>\n",
       "      <td>C</td>\n",
       "      <td>07/09/21</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>07/11/21</td>\n",
       "      <td>12/19/21</td>\n",
       "      <td>161</td>\n",
       "      <td>03/31/22</td>\n",
       "      <td>04/01/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346</td>\n",
       "      <td>13.529</td>\n",
       "      <td>0.621</td>\n",
       "      <td>784.682</td>\n",
       "      <td>400.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847595020</th>\n",
       "      <td>C</td>\n",
       "      <td>12/15/21</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>12/16/21</td>\n",
       "      <td>12/20/21</td>\n",
       "      <td>4</td>\n",
       "      <td>06/08/22</td>\n",
       "      <td>06/06/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>7.331</td>\n",
       "      <td>20.551</td>\n",
       "      <td>4.971</td>\n",
       "      <td>28373.205</td>\n",
       "      <td>3,703.3</td>\n",
       "      <td>2,440.2</td>\n",
       "      <td>1,551.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851185020</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/22/21</td>\n",
       "      <td>12/23/21</td>\n",
       "      <td>12/23/21</td>\n",
       "      <td>0</td>\n",
       "      <td>05/27/22</td>\n",
       "      <td>05/27/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>14.716</td>\n",
       "      <td>11.498</td>\n",
       "      <td>2.984</td>\n",
       "      <td>6082.266</td>\n",
       "      <td>2,905.9</td>\n",
       "      <td>943.8</td>\n",
       "      <td>487.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               statc   one_day  aone_day       dao        da  \\\n",
       "master_deal_no                                                 \n",
       "3846599020         P  12/14/21  12/14/21  12/15/21  12/15/21   \n",
       "3847933020         C  12/16/21       NaN  12/17/21  12/17/21   \n",
       "3848920020         C  07/09/21  12/17/21  07/11/21  12/19/21   \n",
       "3847595020         C  12/15/21  12/17/21  12/16/21  12/20/21   \n",
       "3851185020         C       NaN  12/22/21  12/23/21  12/23/21   \n",
       "\n",
       "                dateannorig_days        de dateeffexp   dw definitive_agt  \\\n",
       "master_deal_no                                                              \n",
       "3846599020                     0       NaN   12/31/22  NaN            Yes   \n",
       "3847933020                     0  05/13/22   06/30/22  NaN            Yes   \n",
       "3848920020                   161  03/31/22   04/01/22  NaN            Yes   \n",
       "3847595020                     4  06/08/22   06/06/22  NaN             No   \n",
       "3851185020                     0  05/27/22   05/27/22  NaN            Yes   \n",
       "\n",
       "                ... pricebook eqvalcf eqvalsales      eqval     tlia     cass  \\\n",
       "master_deal_no  ...                                                             \n",
       "3846599020      ...     6.389  16.389      4.750   5699.204  1,265.1    535.0   \n",
       "3847933020      ...     5.573  59.340      5.089   2456.130    347.3    237.8   \n",
       "3848920020      ...     1.346  13.529      0.621    784.682    400.0    433.0   \n",
       "3847595020      ...     7.331  20.551      4.971  28373.205  3,703.3  2,440.2   \n",
       "3851185020      ...    14.716  11.498      2.984   6082.266  2,905.9    943.8   \n",
       "\n",
       "                   clia lockup dae vest  \n",
       "master_deal_no                           \n",
       "3846599020        205.9     No  No   No  \n",
       "3847933020        147.5     No  No   No  \n",
       "3848920020        201.0     No  No   No  \n",
       "3847595020      1,551.3     No  No   No  \n",
       "3851185020        487.7     No  No   No  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "filepath = f\"{path}/data/df.csv\"\n",
    "df = pd.read_csv(filepath, index_col=0, na_values=['nm', 'np'], low_memory=False)\n",
    "\n",
    "# change column names\n",
    "df.index.name = col_names[0]\n",
    "df.columns = col_names[1:]\n",
    "\n",
    "dsk.print_shape(df)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88550987",
   "metadata": {},
   "source": [
    "# Transform date-like and float-like columns\n",
    "Transform date-like columns to `datetime.date` dtype. Transform float-like columns to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db50bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform date-like columns\n",
    "cols_dt = ['one_day', 'aone_day', 'dao', 'da', 'de', 'dateeffexp', 'dw', 'da_date', 'dateval', 'dcom', 'dcomeff']\n",
    "\n",
    "# apply function to the columns\n",
    "df[cols_dt] = df[cols_dt].apply(dsk.convert_date_str_ser_to_datetime)\n",
    "\n",
    "# transform numeric-like columns\n",
    "cols_float = ['val', 'mv', 'amv', 'pr', 'ppmday', 'ppmwk', 'ppm4wk', 'roe', 'tlia', 'cass', 'clia']\n",
    "\n",
    "# apply function to the columns\n",
    "df[cols_float] = df[cols_float].apply(dsk.convert_num_str_ser_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9719d",
   "metadata": {},
   "source": [
    "# Correct `consido` for some deals manually\n",
    "Correct `consid` for some deals manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8faa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct data errors\n",
    "cols = ['consid', 'consido']\n",
    "df[cols] = dsk.correct_consid(df[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe4be0",
   "metadata": {},
   "source": [
    "# Fill missing `pr_initial` by `pr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5ea267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing `pr_initial` by `pr`\n",
    "df.pr_initial[df.pr_initial.isna()]=df.pr[df.pr_initial.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286aaedf",
   "metadata": {},
   "source": [
    "# save intermediate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1442a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/gqn1skjd0v366h5y3kbms6lh0000gn/T/ipykernel_77522/806000311.py:3: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['statc', 'one_day', 'aone_day', 'dao', 'da', 'de', 'dateeffexp', 'dw',\n",
      "       'definitive_agt', 'da_date', 'dateval', 'dcom', 'dcomeff', 'att',\n",
      "       'attitude_change_yn', 'initial_rec', 'tn', 'ttic', 'tcu', 'texch', 'an',\n",
      "       'apub', 'atic', 'acu', 'anatc', 'aexch', 'cross', 'ttf_macro_desc',\n",
      "       'ttf_mid_desc', 'atf_macro_desc', 'atf_mid_desc', 'valamend',\n",
      "       'consid_struct_desc', 'consid', 'consido', 'consids', 'cha', 'tend',\n",
      "       'term', 'synop', 'hdate', 'hosthprice', 'hval', 'hevent', 'hosthval',\n",
      "       'competecode', 'competeval', 'lbo', 'afinancial', 'alp', 'aspv', 'awk',\n",
      "       'hedge_fund_involv_yn', 'collar', 'lockup', 'dae', 'vest'],\n",
      "      dtype='object')]\n",
      "\n",
      "  df.to_hdf(filepath, key = 'df')\n"
     ]
    }
   ],
   "source": [
    "filepath = f\"{path}/data/df_basic_cleaning.h5\"\n",
    "\n",
    "df.to_hdf(filepath, key = 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb1a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
