{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbbeb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:92% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "from os.path import expanduser\n",
    "## actions required!!!!!!!!!!!!!!!!!!!! change your folder path \n",
    "path = \"~/Documents/G3/MA-prediction\"\n",
    "path = expanduser(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import data_science_MA_kit as dsk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "# import wrds\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb080f6a",
   "metadata": {},
   "source": [
    "# Data Processing Notebooks Outline: \n",
    "\n",
    "We download raw M&A deals data from SDC platinum, and process them in several notebooks (in order):\n",
    "- Notebook 0: basic cleaning.\n",
    "- Notebook 1: match with CRSP database.\n",
    "- Notebook 2: date correction.\n",
    "- Notebook 3: create new variables.\n",
    "- Notebook 4: apply filters\n",
    "\n",
    "General guidelines for these data processing notebooks:\n",
    "- We create new columns (variables)  on all the rows first, before applying  any  filters. \n",
    "- When filtering we should not drop any row directly, in case we want to retrieve them later. Instead we add another column called `retain` to indicate whether to retain the row after applying the filters. \n",
    "- These notebooks shall be highly modular, meaning that almost every data operation should be encapsulated in a function in the helper package. Each function is developed in another individual notebook (thus tens of development notebooks). In this way the end user only needs to read the comment without digging into the codes.\n",
    "- From time to time we save the intermediate result as an `hdf` file, as some codes (especially those querying the CRSP database) need tens of minutes to run. Thus we want to run it just for once and store the results for later use. The advantage of `hdf` over `csv` is that it preserves data type like `datetime.date`. Only when we need to inspect the dataset by `Excel` or `Numbers` shall we save it as `csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f5bfa",
   "metadata": {},
   "source": [
    "## Data Processing 0: Basic Cleaning\n",
    "Specifically in this notebook we will do the following:\n",
    "\n",
    "- Load column names from the report file. Load raw data. Change column names. \n",
    "- Transform date-like columns to `datetime.date` dtype. Transform float-like columns to float.\n",
    "- Correct `consid` for some deals manually.\n",
    "- Fill missing:\n",
    "    - `pr_initial` by `pr`. \n",
    "    - `one_day` by the previous trading day to `dao`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96ca4",
   "metadata": {},
   "source": [
    "# Load data\n",
    "## Load column names\n",
    "Full column names in the raw data are too long and unwieldy to carry out python operations; thus we replace them with the acronyms in the database from the report file. Their correspondence is saved as a `csv` file called `column_names.csv`.  Another comprehensive file `SDC_MA_guide.pdf` explains the exact definition of all the variables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2208ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pricebook',\n",
       " 'eqvalcf',\n",
       " 'eqvalsales',\n",
       " 'eqval',\n",
       " 'tlia',\n",
       " 'cass',\n",
       " 'clia',\n",
       " 'lockup',\n",
       " 'dae',\n",
       " 'vest']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = f\"{path}/data/report.rpt\"\n",
    "# extract colnames from report file. The first name is the index name\n",
    "colnames = dsk.extract_colnames_from_report_file(filepath)\n",
    "# show the last 10 column names\n",
    "colnames[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c68ba",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "Load raw data from the `csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b14076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "filepath = f\"{path}/data/df.csv\"\n",
    "df = pd.read_csv(filepath, index_col=0, na_values=['nm', 'np'], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3d7dc",
   "metadata": {},
   "source": [
    "## Change column names\n",
    "Change column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92c8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full column names\n",
    "colnames_full = list(map(lambda x: \" \".join(x.split()).strip(), [df.index.name] + list(df.columns)))\n",
    "\n",
    "# save the correspondence between acronym and full name for convenience\n",
    "filepath = f\"{path}/data/column_names.csv\"\n",
    "pd.Series(colnames_full, index=colnames, name='column name').to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1a7058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is of size (9854, 94).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statc</th>\n",
       "      <th>one_day</th>\n",
       "      <th>aone_day</th>\n",
       "      <th>dao</th>\n",
       "      <th>da</th>\n",
       "      <th>dateannorig_days</th>\n",
       "      <th>de</th>\n",
       "      <th>dateeffexp</th>\n",
       "      <th>dw</th>\n",
       "      <th>definitive_agt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricebook</th>\n",
       "      <th>eqvalcf</th>\n",
       "      <th>eqvalsales</th>\n",
       "      <th>eqval</th>\n",
       "      <th>tlia</th>\n",
       "      <th>cass</th>\n",
       "      <th>clia</th>\n",
       "      <th>lockup</th>\n",
       "      <th>dae</th>\n",
       "      <th>vest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_deal_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3846599020</th>\n",
       "      <td>C</td>\n",
       "      <td>12/14/21</td>\n",
       "      <td>12/14/21</td>\n",
       "      <td>12/15/21</td>\n",
       "      <td>12/15/21</td>\n",
       "      <td>0</td>\n",
       "      <td>07/06/22</td>\n",
       "      <td>07/06/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>6.389</td>\n",
       "      <td>16.389</td>\n",
       "      <td>4.750</td>\n",
       "      <td>5699.204</td>\n",
       "      <td>1,265.1</td>\n",
       "      <td>535.0</td>\n",
       "      <td>205.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847933020</th>\n",
       "      <td>C</td>\n",
       "      <td>12/16/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>0</td>\n",
       "      <td>05/13/22</td>\n",
       "      <td>06/30/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>5.573</td>\n",
       "      <td>59.340</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2456.130</td>\n",
       "      <td>347.3</td>\n",
       "      <td>237.8</td>\n",
       "      <td>147.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848920020</th>\n",
       "      <td>C</td>\n",
       "      <td>07/09/21</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>07/11/21</td>\n",
       "      <td>12/19/21</td>\n",
       "      <td>161</td>\n",
       "      <td>03/31/22</td>\n",
       "      <td>04/01/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346</td>\n",
       "      <td>13.529</td>\n",
       "      <td>0.621</td>\n",
       "      <td>784.682</td>\n",
       "      <td>400.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847595020</th>\n",
       "      <td>C</td>\n",
       "      <td>12/15/21</td>\n",
       "      <td>12/17/21</td>\n",
       "      <td>12/16/21</td>\n",
       "      <td>12/20/21</td>\n",
       "      <td>4</td>\n",
       "      <td>06/08/22</td>\n",
       "      <td>06/06/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>7.331</td>\n",
       "      <td>20.551</td>\n",
       "      <td>4.971</td>\n",
       "      <td>28373.205</td>\n",
       "      <td>3,703.3</td>\n",
       "      <td>2,440.2</td>\n",
       "      <td>1,551.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851185020</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/22/21</td>\n",
       "      <td>12/23/21</td>\n",
       "      <td>12/23/21</td>\n",
       "      <td>0</td>\n",
       "      <td>05/27/22</td>\n",
       "      <td>05/27/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>14.716</td>\n",
       "      <td>11.498</td>\n",
       "      <td>2.984</td>\n",
       "      <td>6082.266</td>\n",
       "      <td>2,905.9</td>\n",
       "      <td>943.8</td>\n",
       "      <td>487.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               statc   one_day  aone_day       dao        da  \\\n",
       "master_deal_no                                                 \n",
       "3846599020         C  12/14/21  12/14/21  12/15/21  12/15/21   \n",
       "3847933020         C  12/16/21       NaN  12/17/21  12/17/21   \n",
       "3848920020         C  07/09/21  12/17/21  07/11/21  12/19/21   \n",
       "3847595020         C  12/15/21  12/17/21  12/16/21  12/20/21   \n",
       "3851185020         C       NaN  12/22/21  12/23/21  12/23/21   \n",
       "\n",
       "                dateannorig_days        de dateeffexp   dw definitive_agt  \\\n",
       "master_deal_no                                                              \n",
       "3846599020                     0  07/06/22   07/06/22  NaN            Yes   \n",
       "3847933020                     0  05/13/22   06/30/22  NaN            Yes   \n",
       "3848920020                   161  03/31/22   04/01/22  NaN            Yes   \n",
       "3847595020                     4  06/08/22   06/06/22  NaN             No   \n",
       "3851185020                     0  05/27/22   05/27/22  NaN            Yes   \n",
       "\n",
       "                ... pricebook eqvalcf eqvalsales      eqval     tlia     cass  \\\n",
       "master_deal_no  ...                                                             \n",
       "3846599020      ...     6.389  16.389      4.750   5699.204  1,265.1    535.0   \n",
       "3847933020      ...     5.573  59.340      5.089   2456.130    347.3    237.8   \n",
       "3848920020      ...     1.346  13.529      0.621    784.682    400.0    433.0   \n",
       "3847595020      ...     7.331  20.551      4.971  28373.205  3,703.3  2,440.2   \n",
       "3851185020      ...    14.716  11.498      2.984   6082.266  2,905.9    943.8   \n",
       "\n",
       "                   clia lockup dae vest  \n",
       "master_deal_no                           \n",
       "3846599020        205.9     No  No   No  \n",
       "3847933020        147.5     No  No   No  \n",
       "3848920020        201.0     No  No   No  \n",
       "3847595020      1,551.3     No  No   No  \n",
       "3851185020        487.7     No  No   No  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change column names\n",
    "df.index.name = colnames[0]\n",
    "df.columns = colnames[1:]\n",
    "\n",
    "dsk.print_shape(df)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88550987",
   "metadata": {},
   "source": [
    "# Transform date-like and float-like columns\n",
    "Transform date-like columns to `datetime.date` dtype. Transform float-like columns to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db50bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# date-like columns to transform\n",
    "cols_dt = ['one_day', 'aone_day', 'dao', 'da', 'de', 'dateeffexp', 'dw', 'da_date', 'dateval', 'dcom', 'dcomeff']\n",
    "\n",
    "# apply function to each column\n",
    "df[cols_dt] = df[cols_dt].apply(dsk.convert_date_str_ser_to_datetime)\n",
    "\n",
    "# numeric-like columns to transform\n",
    "cols_float = ['val', 'mv', 'amv', 'pr', 'ppmday', 'ppmwk', 'ppm4wk', 'roe', 'tlia', 'cass', 'clia']\n",
    "\n",
    "# apply function to each column\n",
    "df[cols_float] = df[cols_float].apply(dsk.convert_num_str_ser_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9719d",
   "metadata": {},
   "source": [
    "# Correct `consido` for some deals manually\n",
    "Correct `consid` for some deals manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8faa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct data errors\n",
    "cols = ['consid', 'consido']\n",
    "df[cols] = dsk.correct_consid(df[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe4be0",
   "metadata": {},
   "source": [
    "# Fill missing \n",
    "## `pr_initial` by `pr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5ea267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing `pr_initial` by `pr`\n",
    "df.pr_initial[df.pr_initial.isna()]=df.pr[df.pr_initial.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ab3fcf",
   "metadata": {},
   "source": [
    "## `one_day` by the previous trading day to `dao`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc705ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing one_day by the previous trading day to <dao>\n",
    "df.one_day[df.one_day.isna()] = dsk.get_trading_day_offset(df.dao[df.one_day.isna()], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286aaedf",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1442a5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/gqn1skjd0v366h5y3kbms6lh0000gn/T/ipykernel_97680/2385045077.py:3: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['statc', 'one_day', 'aone_day', 'dao', 'da', 'de', 'dateeffexp', 'dw',\n",
      "       'definitive_agt', 'da_date', 'dateval', 'dcom', 'dcomeff', 'att',\n",
      "       'attitude_change_yn', 'initial_rec', 'tn', 'ttic', 'tcu', 'texch', 'an',\n",
      "       'apub', 'atic', 'acu', 'anatc', 'aexch', 'cross', 'ttf_macro_desc',\n",
      "       'ttf_mid_desc', 'atf_macro_desc', 'atf_mid_desc', 'valamend',\n",
      "       'consid_struct_desc', 'consid', 'consido', 'consids', 'cha', 'tend',\n",
      "       'term', 'synop', 'hdate', 'hosthprice', 'hval', 'hevent', 'hosthval',\n",
      "       'competecode', 'competeval', 'lbo', 'afinancial', 'alp', 'aspv', 'awk',\n",
      "       'hedge_fund_involv_yn', 'collar', 'lockup', 'dae', 'vest'],\n",
      "      dtype='object')]\n",
      "\n",
      "  df.to_hdf(filepath, key = 'df', mode='w')\n"
     ]
    }
   ],
   "source": [
    "filepath = f\"{path}/data/df_basic_cleaning.h5\"\n",
    "\n",
    "df.to_hdf(filepath, key = 'df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1fbcd8",
   "metadata": {},
   "source": [
    "# Combine with the CRSP result\n",
    "If later we need to modify this notebook, we can combine the new result with the CRSP result in this block. This is to save the tens of minutes pulling data from CRSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5262b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = f\"{path}/data/CRSP_results.h5\"\n",
    "# CRSP_results = pd.read_hdf(filepath)\n",
    "\n",
    "# # combine CRSP result with the dataset after basic cleaning\n",
    "# loc_names = ['ttic', 'ttic', 'tcu', 'tn'] + ['atic', 'atic', 'acu', 'an'] + ['att'] * 5\n",
    "# dsk.insert_cols(df, loc_names, CRSP_results.columns, CRSP_results)\n",
    "\n",
    "# filepath = f\"{path}/data/df_merge_CRSP.h5\"\n",
    "# df.to_hdf(filepath, key = 'df', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
