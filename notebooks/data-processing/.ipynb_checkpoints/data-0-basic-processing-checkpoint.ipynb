{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbbeb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "from os.path import expanduser\n",
    "## actions required!!!!!!!!!!!!!!!!!!!! change your folder path \n",
    "path = \"~/Documents/G3/MA-prediction\"\n",
    "path = expanduser(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e4ab42-12ad-4c85-9a65-2bff7d2f4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MA_prediction.utils import *\n",
    "from MA_prediction.mkt_calendar import *\n",
    "from MA_prediction.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f5bfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  data-0: basic processing\n",
    "In this notebook we will do very basic data processing and filtering:\n",
    "\n",
    "- Process column names: replace full names with acronyms.\n",
    "- Process data types: convert dtypes for float-like and date-like (saved as `datetime.date`) columns. \n",
    "- Process dates:\n",
    "    - some dates must be trading days. \n",
    "    - original annnouncement date `dao` to be before announcement date `da`. Later we would adjust it to be within $[\\text{da}-126, \\text{da}]$ when calculating premiums.\n",
    "    - create `dr` date of resolution (end of deal), that is effective date `de` for completed deals, withdrawal date `dw` for withdrawn deals and missing for pending deals. Later for completed deals we will replace `de` with `delist_date` found in CRSP.\n",
    "- Clean tickers and cusips.\n",
    "- Process deal consideration: some manual correction.\n",
    "- Fill missing `pr_initial` by `pr`.\n",
    "\n",
    "Basic filterings: delete the following deals\n",
    "\n",
    "- not applicable to our research (detected manually).\n",
    "- Price is missing.\n",
    "- Deal consideration is missing. \n",
    "\n",
    "We would delete those undesired deals as they are impossible to use in either the prediction model, or in backtesting. Later when applying filters, we would not delete data directly, but instead use a column `retain` to indicate whether the deal is retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0992c-c3ea-41b6-ab3f-93fda775fba2",
   "metadata": {},
   "source": [
    "## I/O    \n",
    "- Input: \n",
    "    - `data/raw/df.csv`.\n",
    "- Output: \n",
    "    - `data/intermediate/df_basic_processing.h5`, and a `csv` file.\n",
    "    - `data/reference/column_names.csv`\n",
    "    - `data/reference/filters_basic.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96ca4",
   "metadata": {},
   "source": [
    "# Load data and change column names\n",
    "Full column names in the raw data are too long and unwieldy to carry out python operations; thus we replace them with the acronyms in the database from the report file. Their correspondence is saved as a `csv` file called `column_names.csv`.  Another comprehensive file `SDC_MA_guide.pdf` explains the exact definition of all the variables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b14076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pricebook',\n",
       " 'eqvalcf',\n",
       " 'eqvalsales',\n",
       " 'eqval',\n",
       " 'tlia',\n",
       " 'cass',\n",
       " 'clia',\n",
       " 'lockup',\n",
       " 'dae',\n",
       " 'vest']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw dataset\n",
    "filepath = f\"{path}/data/raw/df.csv\"\n",
    "df = pd.read_csv(filepath, index_col=0, na_values=['nm', 'np'], low_memory=False)\n",
    "\n",
    "# extract full column names\n",
    "colnames_full = list(map(lambda x: \" \".join(x.split()).strip(), [df.index.name] + list(df.columns)))\n",
    "\n",
    "# extract acronyms of variables from the report file; the first name is that of index.\n",
    "filepath = f\"{path}/data/reference/report.rpt\"\n",
    "colnames = extract_colnames_from_report_file(filepath)\n",
    "# show the last 10 column acronyms\n",
    "colnames[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1a7058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is of size (12082, 94).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statc</th>\n",
       "      <th>one_day</th>\n",
       "      <th>aone_day</th>\n",
       "      <th>dao</th>\n",
       "      <th>da</th>\n",
       "      <th>dateannorig_days</th>\n",
       "      <th>de</th>\n",
       "      <th>dateeffexp</th>\n",
       "      <th>dw</th>\n",
       "      <th>definitive_agt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricebook</th>\n",
       "      <th>eqvalcf</th>\n",
       "      <th>eqvalsales</th>\n",
       "      <th>eqval</th>\n",
       "      <th>tlia</th>\n",
       "      <th>cass</th>\n",
       "      <th>clia</th>\n",
       "      <th>lockup</th>\n",
       "      <th>dae</th>\n",
       "      <th>vest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_deal_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3992461020</th>\n",
       "      <td>P</td>\n",
       "      <td>10/24/22</td>\n",
       "      <td>12/16/22</td>\n",
       "      <td>10/25/22</td>\n",
       "      <td>12/18/22</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/31/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>8.659</td>\n",
       "      <td>16.011</td>\n",
       "      <td>2.087</td>\n",
       "      <td>4547.200</td>\n",
       "      <td>1,748.5</td>\n",
       "      <td>1,001.7</td>\n",
       "      <td>802.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015877020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/16/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/19/22</td>\n",
       "      <td>12/19/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/28/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>4.839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752</td>\n",
       "      <td>16.141</td>\n",
       "      <td>18.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016515020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/14/22</td>\n",
       "      <td>12/19/22</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/30/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017224020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>12/21/22</td>\n",
       "      <td>12/21/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/31/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.912</td>\n",
       "      <td>55.152</td>\n",
       "      <td>61.3</td>\n",
       "      <td>97.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019588020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/23/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/22</td>\n",
       "      <td>12/27/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895</td>\n",
       "      <td>25.412</td>\n",
       "      <td>52.4</td>\n",
       "      <td>34.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               statc   one_day  aone_day       dao        da  \\\n",
       "master_deal_no                                                 \n",
       "3992461020         P  10/24/22  12/16/22  10/25/22  12/18/22   \n",
       "4015877020         P  12/16/22       NaN  12/19/22  12/19/22   \n",
       "4016515020         P  12/14/22  12/19/22  12/20/22  12/20/22   \n",
       "4017224020         P  12/20/22  12/20/22  12/21/22  12/21/22   \n",
       "4019588020         P  12/23/22       NaN  12/27/22  12/27/22   \n",
       "\n",
       "                dateannorig_days   de dateeffexp   dw definitive_agt  ...  \\\n",
       "master_deal_no                                                        ...   \n",
       "3992461020                    54  NaN   12/31/23  NaN            Yes  ...   \n",
       "4015877020                     0  NaN   02/28/23  NaN            Yes  ...   \n",
       "4016515020                     0  NaN   06/30/23  NaN            Yes  ...   \n",
       "4017224020                     0  NaN   03/31/23  NaN            Yes  ...   \n",
       "4019588020                     0  NaN        NaN  NaN             No  ...   \n",
       "\n",
       "               pricebook eqvalcf eqvalsales     eqval     tlia     cass  \\\n",
       "master_deal_no                                                            \n",
       "3992461020         8.659  16.011      2.087  4547.200  1,748.5  1,001.7   \n",
       "4015877020         4.839     NaN      0.752    16.141     18.3     14.2   \n",
       "4016515020           NaN     NaN        NaN    52.581      NaN      NaN   \n",
       "4017224020         0.750     NaN      2.912    55.152     61.3     97.6   \n",
       "4019588020           NaN     NaN      0.895    25.412     52.4     34.1   \n",
       "\n",
       "                 clia lockup dae vest  \n",
       "master_deal_no                         \n",
       "3992461020      802.9     No  No   No  \n",
       "4015877020       16.4     No  No   No  \n",
       "4016515020        NaN     No  No   No  \n",
       "4017224020       11.2     No  No   No  \n",
       "4019588020       36.4     No  No   No  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change column names\n",
    "df.index.name = colnames[0]\n",
    "df.columns = colnames[1:]\n",
    "\n",
    "print_shape(df)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92c8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the correspondence between acronym and full name for convenience\n",
    "filepath = f\"{path}/data/reference/column_names.csv\"\n",
    "pd.Series(colnames_full, index=colnames, name='column name').to_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88550987",
   "metadata": {},
   "source": [
    "# Transform float-like and date-like datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c33e26-2064-4d22-84de-094d759050ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric-like columns to transform\n",
    "cols_float = ['val', 'mv', 'amv', 'pr', 'ppmday', 'ppmwk', 'ppm4wk', 'roe', 'tlia', 'cass', 'clia']\n",
    "# apply function to each column\n",
    "df[cols_float] = df[cols_float].apply(convert_num_str_ser_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5495367-477f-4cbc-9dbb-500424c664dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date-like columns to transform\n",
    "cols_dt = ['one_day', 'aone_day', 'dao', 'da', 'de', 'dateeffexp', 'dw', 'da_date', 'dateval', 'dcom', 'dcomeff']\n",
    "# apply function to each column\n",
    "df[cols_dt] = df[cols_dt].apply(convert_date_str_ser_to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca2c567-79a4-4e95-b878-616b095d0b12",
   "metadata": {},
   "source": [
    "# Correct some dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db50bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert some date columns to the next trading days (incl. the day itself)\n",
    "cols_trading_day = ['dao', 'da', 'de', 'dw', 'dateval', 'dcom', 'dcomeff']\n",
    "df[cols_trading_day] = df[cols_trading_day].apply(lambda x: get_trading_day_offset(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60355643-7370-48d1-91bb-d511ccafa63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct some dates\n",
    "## dao\n",
    "df.dao = np.minimum(df.dao, df.da)\n",
    "\n",
    "## prior trading days\n",
    "df.one_day = get_trading_day_offset(df.dao, -1)\n",
    "df.aone_day = get_trading_day_offset(df.da, -1)\n",
    "\n",
    "## create date of resolution\n",
    "insert_cols(df, 'definitive_agt', 'dr', np.nan)\n",
    "df.dr[df.statc.eq('C')] = df.de[df.statc.eq('C')]\n",
    "df.dr[df.statc.eq('W')] = df.dw[df.statc.eq('W')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7058c85-274c-43bc-9c87-c90098dc1304",
   "metadata": {},
   "source": [
    "# clean tickers and cusips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f8107c-b159-44c0-ae49-bb22c6652375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean ticker and cusip\n",
    "df.ttic = df.ttic.str.replace(\"'\", \"\")\n",
    "df.atic = df.atic.str.replace(\"'\", \"\")\n",
    "df.tcu = df.tcu.str.upper()\n",
    "df.acu = df.acu.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9719d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Correct deal consideration manually\n",
    "These are database error / inconsistency that I found during analysis, mainly about the string format of deal consideration. Let us try to correct as many as possible though this can never be comprehensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53fe3061-a70f-4956-8bfe-4d87c01667af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct consideration\n",
    "cols = ['consid', 'consido']\n",
    "df[cols] = correct_consid(df[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6388c890-6a31-4bc3-aee9-7be0887a5cba",
   "metadata": {},
   "source": [
    "# Basic Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "198d5b0c-ed7b-41f1-a2e8-698549c28716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file for output\n",
    "txt_filepath = f\"{path}/data/reference/filters_basic.txt\"\n",
    "txt_file = open(txt_filepath, \"w\")\n",
    "\n",
    "# \n",
    "num = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6006084d-32fa-482c-8316-45a98cb1a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete 1633 deals due to missing pricing information. 12082 -> 10449\n"
     ]
    }
   ],
   "source": [
    "num_old = num\n",
    "\n",
    "# fill missing initial price\n",
    "df.pr_initial[df.pr_initial.isna()] = df.pr[df.pr_initial.isna()]\n",
    "\n",
    "# drop missing price\n",
    "df = df[df.pr.notna()]\n",
    "\n",
    "num = len(df)\n",
    "string = f\"delete {num_old-num} deals due to missing pricing information. {num_old} -> {num}\"\n",
    "print_and_save_string(string, txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb83beff-011f-47c1-ad9c-5891ace9419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete 3 deals due to missing consideration. 10449 -> 10446\n"
     ]
    }
   ],
   "source": [
    "num_old = num\n",
    "# drop missing consideration\n",
    "df = df[df.consid.notna()]\n",
    "\n",
    "num = len(df)\n",
    "string = f\"delete {num_old-num} deals due to missing consideration. {num_old} -> {num}\"\n",
    "print_and_save_string(string, txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e80f6b58-babf-4658-89f2-e899639af643",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286aaedf",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1442a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf\n",
    "filepath = f\"{path}/data/intermediate/df_basic_processing.h5\"\n",
    "\n",
    "df.to_hdf(filepath, key = 'df', mode='w')\n",
    "df.to_csv(filepath.replace(\"h5\", \"csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
