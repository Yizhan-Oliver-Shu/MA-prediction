{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbbeb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "from os.path import expanduser\n",
    "## actions required!!!!!!!!!!!!!!!!!!!! change your folder path \n",
    "path = \"~/Documents/G3/MA-prediction\"\n",
    "path = expanduser(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "# import wrds\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81e4ab42-12ad-4c85-9a65-2bff7d2f4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MA_prediction.preprocessing import *\n",
    "from MA_prediction.mkt_calendar import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb080f6a",
   "metadata": {},
   "source": [
    "# Data Processing Notebooks Outline: \n",
    "\n",
    "We downloaded raw M&A deals data from SDC platinum, and process them in several notebooks (in order):\n",
    "\n",
    "- Notebook 0: basic cleaning.\n",
    "- Notebook 1: match with CRSP database.\n",
    "- Notebook 2: date correction.\n",
    "- Notebook 3: pull market data from CRSP.\n",
    "- Notebook 4: create new variables.\n",
    "- Notebook 5: process market data.\n",
    "- Notebook 6: create variables for prediction model.\n",
    "- Notebook 7: apply filters.\n",
    "\n",
    "General guidelines for these data processing notebooks:\n",
    "\n",
    "- We create new columns (variables)  on all the rows first, before applying  any  filters. \n",
    "- When filtering we should not drop any row directly, in case we want to retrieve them later. Instead we add another column called `retain` to indicate whether to retain the row after applying the filters. \n",
    "- These notebooks shall be highly modular, meaning that almost every data operation should be encapsulated in a function in the helper package. Each function is developed in another individual notebook (thus tens of development notebooks). In this way the end user only needs to read the documentation without digging into the codes.\n",
    "- From time to time we save the intermediate result as an `hdf` file, as some codes (especially those querying the CRSP database) need tens of minutes to run. Thus we want to run it just for once and store the results for later use. The advantage of `hdf` over `csv` is that it preserves data type like `datetime.date`. Only when we need to inspect the dataset by `Excel` or `Numbers` shall we save it as `csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f5bfa",
   "metadata": {},
   "source": [
    "## Data Processing 0: Basic Cleaning\n",
    "Specifically in this notebook we will do the following:\n",
    "\n",
    "- Load column names from the report file. Load raw data. Change column names. \n",
    "- Transform date-like columns to `datetime.date` dtype. Transform float-like columns to float.\n",
    "- Correct `consid` for some deals manually.\n",
    "- Fill missing:\n",
    "    - `pr_initial` by `pr`. \n",
    "    - `one_day` by the previous trading day to `dao`.\n",
    "    \n",
    "## I/O    \n",
    "- Input: \n",
    "    - `df.csv`\n",
    "- Output: \n",
    "    - `df_basic_cleaning.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96ca4",
   "metadata": {},
   "source": [
    "# Load data\n",
    "## Load column names\n",
    "Full column names in the raw data are too long and unwieldy to carry out python operations; thus we replace them with the acronyms in the database from the report file. Their correspondence is saved as a `csv` file called `column_names.csv`.  Another comprehensive file `SDC_MA_guide.pdf` explains the exact definition of all the variables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2208ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pricebook',\n",
       " 'eqvalcf',\n",
       " 'eqvalsales',\n",
       " 'eqval',\n",
       " 'tlia',\n",
       " 'cass',\n",
       " 'clia',\n",
       " 'lockup',\n",
       " 'dae',\n",
       " 'vest']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = f\"{path}/data/reference/report.rpt\"\n",
    "# extract acronyms of variables from the report file; the first name is name of index. Later replace colnames with them.\n",
    "colnames = extract_colnames_from_report_file(filepath)\n",
    "# show the last 10 column names\n",
    "colnames[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c68ba",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "Load raw data from the `csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b14076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "filepath = f\"{path}/data/raw/df.csv\"\n",
    "df = pd.read_csv(filepath, index_col=0, na_values=['nm', 'np'], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3d7dc",
   "metadata": {},
   "source": [
    "## Change column names\n",
    "Change column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92c8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract full column names\n",
    "colnames_full = list(map(lambda x: \" \".join(x.split()).strip(), [df.index.name] + list(df.columns)))\n",
    "\n",
    "# save the correspondence between acronym and full name for convenience\n",
    "filepath = f\"{path}/data/reference/column_names.csv\"\n",
    "pd.Series(colnames_full, index=colnames, name='column name').to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1a7058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is of size (12082, 94).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statc</th>\n",
       "      <th>one_day</th>\n",
       "      <th>aone_day</th>\n",
       "      <th>dao</th>\n",
       "      <th>da</th>\n",
       "      <th>dateannorig_days</th>\n",
       "      <th>de</th>\n",
       "      <th>dateeffexp</th>\n",
       "      <th>dw</th>\n",
       "      <th>definitive_agt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricebook</th>\n",
       "      <th>eqvalcf</th>\n",
       "      <th>eqvalsales</th>\n",
       "      <th>eqval</th>\n",
       "      <th>tlia</th>\n",
       "      <th>cass</th>\n",
       "      <th>clia</th>\n",
       "      <th>lockup</th>\n",
       "      <th>dae</th>\n",
       "      <th>vest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_deal_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3992461020</th>\n",
       "      <td>P</td>\n",
       "      <td>10/24/22</td>\n",
       "      <td>12/16/22</td>\n",
       "      <td>10/25/22</td>\n",
       "      <td>12/18/22</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/31/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>8.659</td>\n",
       "      <td>16.011</td>\n",
       "      <td>2.087</td>\n",
       "      <td>4547.200</td>\n",
       "      <td>1,748.5</td>\n",
       "      <td>1,001.7</td>\n",
       "      <td>802.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015877020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/16/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/19/22</td>\n",
       "      <td>12/19/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/28/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>4.839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752</td>\n",
       "      <td>16.141</td>\n",
       "      <td>18.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016515020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/14/22</td>\n",
       "      <td>12/19/22</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/30/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017224020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>12/20/22</td>\n",
       "      <td>12/21/22</td>\n",
       "      <td>12/21/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/31/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.912</td>\n",
       "      <td>55.152</td>\n",
       "      <td>61.3</td>\n",
       "      <td>97.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019588020</th>\n",
       "      <td>P</td>\n",
       "      <td>12/23/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/22</td>\n",
       "      <td>12/27/22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895</td>\n",
       "      <td>25.412</td>\n",
       "      <td>52.4</td>\n",
       "      <td>34.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               statc   one_day  aone_day       dao        da  \\\n",
       "master_deal_no                                                 \n",
       "3992461020         P  10/24/22  12/16/22  10/25/22  12/18/22   \n",
       "4015877020         P  12/16/22       NaN  12/19/22  12/19/22   \n",
       "4016515020         P  12/14/22  12/19/22  12/20/22  12/20/22   \n",
       "4017224020         P  12/20/22  12/20/22  12/21/22  12/21/22   \n",
       "4019588020         P  12/23/22       NaN  12/27/22  12/27/22   \n",
       "\n",
       "                dateannorig_days   de dateeffexp   dw definitive_agt  ...  \\\n",
       "master_deal_no                                                        ...   \n",
       "3992461020                    54  NaN   12/31/23  NaN            Yes  ...   \n",
       "4015877020                     0  NaN   02/28/23  NaN            Yes  ...   \n",
       "4016515020                     0  NaN   06/30/23  NaN            Yes  ...   \n",
       "4017224020                     0  NaN   03/31/23  NaN            Yes  ...   \n",
       "4019588020                     0  NaN        NaN  NaN             No  ...   \n",
       "\n",
       "               pricebook eqvalcf eqvalsales     eqval     tlia     cass  \\\n",
       "master_deal_no                                                            \n",
       "3992461020         8.659  16.011      2.087  4547.200  1,748.5  1,001.7   \n",
       "4015877020         4.839     NaN      0.752    16.141     18.3     14.2   \n",
       "4016515020           NaN     NaN        NaN    52.581      NaN      NaN   \n",
       "4017224020         0.750     NaN      2.912    55.152     61.3     97.6   \n",
       "4019588020           NaN     NaN      0.895    25.412     52.4     34.1   \n",
       "\n",
       "                 clia lockup dae vest  \n",
       "master_deal_no                         \n",
       "3992461020      802.9     No  No   No  \n",
       "4015877020       16.4     No  No   No  \n",
       "4016515020        NaN     No  No   No  \n",
       "4017224020       11.2     No  No   No  \n",
       "4019588020       36.4     No  No   No  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change column names\n",
    "df.index.name = colnames[0]\n",
    "df.columns = colnames[1:]\n",
    "\n",
    "print_shape(df)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88550987",
   "metadata": {},
   "source": [
    "# Transform date-like and float-like columns\n",
    "Transform date-like columns to `datetime.date` dtype. Transform float-like columns to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db50bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'atof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m cols_float \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppmday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppmwk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppm4wk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtlia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclia\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# apply function to each column\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df[cols_float] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_float\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_num_str_ser_to_float\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ma-wrds/lib/python3.11/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/ma-wrds/lib/python3.11/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ma-wrds/lib/python3.11/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/mambaforge/envs/ma-wrds/lib/python3.11/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/G3/MA-prediction/MA_prediction/preprocessing.py:78\u001b[0m, in \u001b[0;36mconvert_num_str_ser_to_float\u001b[0;34m(ser)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_num_str_ser_to_float\u001b[39m(ser):\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    convert a series of numeric-like strings (e.g. '1,000') to floats. NA is allowed in <ser>.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    a series of floats.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mmap(\u001b[43matof\u001b[49m, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'atof' is not defined"
     ]
    }
   ],
   "source": [
    "# date-like columns to transform\n",
    "cols_dt = ['one_day', 'aone_day', 'dao', 'da', 'de', 'dateeffexp', 'dw', 'da_date', 'dateval', 'dcom', 'dcomeff']\n",
    "\n",
    "# apply function to each column\n",
    "df[cols_dt] = df[cols_dt].apply(convert_date_str_ser_to_datetime)\n",
    "\n",
    "# numeric-like columns to transform\n",
    "cols_float = ['val', 'mv', 'amv', 'pr', 'ppmday', 'ppmwk', 'ppm4wk', 'roe', 'tlia', 'cass', 'clia']\n",
    "\n",
    "# apply function to each column\n",
    "df[cols_float] = df[cols_float].apply(convert_num_str_ser_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9719d",
   "metadata": {},
   "source": [
    "# Correct `consido` for some deals manually\n",
    "Correct `consid` for some deals manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8faa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct data errors\n",
    "cols = ['consid', 'consido']\n",
    "df[cols] = correct_consid(df[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe4be0",
   "metadata": {},
   "source": [
    "# Fill missing \n",
    "## `pr_initial` by `pr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5ea267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing `pr_initial` by `pr`\n",
    "df.pr_initial[df.pr_initial.isna()]=df.pr[df.pr_initial.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ab3fcf",
   "metadata": {},
   "source": [
    "## `one_day` by the previous trading day to `dao`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc705ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing one_day by the previous trading day to <dao>\n",
    "df.one_day[df.one_day.isna()] = get_trading_day_offset(df.dao[df.one_day.isna()], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286aaedf",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1442a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"{path}/data/intermediate/df_basic_cleaning.h5\"\n",
    "\n",
    "df.to_hdf(filepath, key = 'df', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
