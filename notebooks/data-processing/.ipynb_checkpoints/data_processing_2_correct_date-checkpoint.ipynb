{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed9c5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:92% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:92% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "from os.path import expanduser\n",
    "## actions required!!!!!!!!!!!!!!!!!!!! change your folder path \n",
    "path = \"~/Documents/G3/MA-prediction\"\n",
    "path = expanduser(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import data_science_MA_kit as dsk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import wrds\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263019f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [yizhan]:olivershu\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "Create .pgpass file now [y/n]?: y\n",
      "Created .pgpass file successfully.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7981e33",
   "metadata": {},
   "source": [
    "# Data preprocessing 2: Date Correction\n",
    "\n",
    "Dates are very essential in corporate events, during which volumes and volatility are extremely high. As a result, messing up event date by even only one trading day would affect return calculation to some extent. We define the dates as below:\n",
    "\n",
    "- `dao`: max(min(`dao`, `da`), 126 trading days before `da`) \n",
    "- `da`: announcement date, the next trading day after announcement. Usually this day will see the highest trading volumes. The complexity is that the official announcement on `da` provided in the database can be both on the morning or in the evening, which may affect the current or the next trading day. Thus we correct announcement date to be the one of `da` and `da`+1 trading day that has the higher trading volumes.\n",
    "- `dr`: resolution date.\n",
    "    - for completed deals, it is the effective date, defined as the first trading day after the equity's last trading day. We use the `delist_date` provided in CRSP. It not available, we use just `de`.\n",
    "    - for withdrawn deals, it is the withdrawal date, defined as the first trading day after announcement of withdrawal. Same as `da`, we correct it to be one of `dw` and `dw` + 1 trading day with the higher trading volumes.\n",
    "\n",
    "- After correcting the dates, we create the deal duration, which is the number of trading days between `da_corrected` and `dr_corrected`.\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "- correct `dao`, `one_day`: `dao` cannot be 126 trading days before announcement.\n",
    "- correct `da`: one of `da` and `da`+1 trading day that has the higher trading volumes.\n",
    "- correct `dr`: \n",
    "    - `delist_date` or `de` for completed deals.\n",
    "    - one of `dw` or `dw`+1 trading day that has the higher trading volumes.\n",
    "- create deal duration: the number of trading days between `da_corrected` and `dr_corrected`.\n",
    "\n",
    "## I/O\n",
    "\n",
    "- Input:\n",
    "    - `df_merge_CRSP.h5`\n",
    "    \n",
    "- Output:\n",
    "    - `df_dates_corrected.h5`\n",
    "    - `dates_corrected.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db0a78",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6c21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"{path}/data/df_merge_CRSP.h5\"\n",
    "df = pd.read_hdf(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfcdda",
   "metadata": {},
   "source": [
    "# `dao_corrected` and `one_day_new`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250391c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dao_corrected should be ealier than da\n",
    "dsk.insert_cols(df, 'dao', 'dao_corrected', np.minimum(df.da, df.dao))\n",
    "# dao_corrected should be within 6 months before the announcement\n",
    "df.dao_corrected = np.maximum(df.dao_corrected, dsk.get_trading_day_offset(df.da, -126))\n",
    "\n",
    "# one_day_new is the previous trading day to dao_new\n",
    "dsk.insert_cols(df, 'one_day', 'one_day_corrected', dsk.get_trading_day_offset(df.dao_corrected, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807a267",
   "metadata": {},
   "source": [
    "# correct original `one_day`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be13bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some `one_day`s in the database are not trading days\n",
    "one_day_next_trading_day = dsk.get_trading_day_offset(df.one_day, 0)\n",
    "one_day_prior_trading_day = dsk.get_trading_day_offset(df.one_day, -1)\n",
    "# pick the indices whose one_day is not a trading day\n",
    "index_oneday_not_trading_day = df.index[one_day_next_trading_day.ne(df.one_day)]\n",
    "# adjust them to the previous trading day\n",
    "df.one_day[index_oneday_not_trading_day] = one_day_prior_trading_day[index_oneday_not_trading_day]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2c888",
   "metadata": {},
   "source": [
    "# correct `da`\n",
    "we define `da` to be the next trading day after announcement, which should have the highest trading volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c934ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_vol_from_ser_CRSP(ser, db=None):\n",
    "    \"\"\"\n",
    "    ser has three values (permno, start_date, end_date)\n",
    "    \"\"\"\n",
    "    return dsk.get_stock_market_data_daily_CRSP(ser.iloc[0], start_date=ser.iloc[1], end_date=ser.iloc[2], cols=['vol'], db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2e5e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 12031/12031 [02:54<00:00, 68.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# the first trading day after `da`\n",
    "da = dsk.get_trading_day_offset(df.da, 0)\n",
    "# the second trading day after `da`\n",
    "da_plus_one_day = dsk.get_trading_day_offset(df.da, 1)\n",
    "# pull trading volume data from CRSP. take 2-4 mins\n",
    "df_tpermno_da_da_plus_one = pd.concat([df.tpermno, da, da_plus_one_day], axis=1)\n",
    "volumes_da_df = dsk.apply_func_to_ser_df(df_tpermno_da_da_plus_one, \n",
    "                                          get_stock_vol_from_ser_CRSP, \n",
    "                                          return_as_df=True, \n",
    "                                          use_new_cols=['vol_da', 'vol_da_plus_one'],\n",
    "                                                        db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26cd7f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3761\n"
     ]
    }
   ],
   "source": [
    "dsk.insert_cols(df, 'da', 'da_corrected', da)\n",
    "# \n",
    "index_da_to_correct = df.index[volumes_da_df.vol_da_plus_one.gt(volumes_da_df.vol_da, fill_value=0)]\n",
    "print(len(index_da_to_correct))\n",
    "df.da_corrected[index_da_to_correct] = da_plus_one_day[index_da_to_correct]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189155f",
   "metadata": {},
   "source": [
    "# create `dr`\n",
    "We first create a raw `dr` using SDC dates, i.e. `de` for completed deals and `dw` for withdrawn deals.\n",
    "\n",
    "Then we create a `dr_corrected` by our method:\n",
    "\n",
    "- for completed deals, `dr_corrected` is the delisting date, the next trading day after last trade date, or just `de` if delisting date is not available.\n",
    "- for withdrawn deals, `dr_corrected` is the next trading date after announcement of withdrawal, which should also have high trading volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8adfb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a `dr` from the database\n",
    "dsk.insert_cols(df, 'definitive_agt', 'dr', np.nan)\n",
    "#\n",
    "df.dr[df.statc.eq('C')] = df.de[df.statc.eq('C')]\n",
    "df.dr[df.statc.eq('W')] = df.dw[df.statc.eq('W')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065db70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dr corrected by us\n",
    "dsk.insert_cols(df, 'definitive_agt', 'dr_corrected', np.nan)\n",
    "\n",
    "# for completed deals, fill date of resolution by the delisting date\n",
    "df.dr_corrected[df.statc.eq('C')] = df.delist_date[df.statc.eq('C')]\n",
    "# for completed deals where delisting date is missing, fill it by just `de`\n",
    "index_na_delist_date = df.index[df.statc.eq('C')&df.delist_date.isna()]\n",
    "df.dr_corrected[index_na_delist_date] = df.de[index_na_delist_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9ffbfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2891/2891 [00:39<00:00, 72.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# for withdrawn deals, fill date of resolution to one of dw and dw+1 with the higher trading volumes\n",
    "# extract withdrawn deals\n",
    "df_w = df.loc[df.statc.eq('W')]\n",
    "# \n",
    "dw = dsk.get_trading_day_offset(df_w.dw, 0)\n",
    "dw_plus_one_day = dsk.get_trading_day_offset(df_w.dw, 1)\n",
    "# \n",
    "df_tpermno_dw_dw_plus_one = pd.concat([df_w.tpermno, dw, dw_plus_one_day], axis=1)\n",
    "volumes_dw_df = dsk.apply_func_to_ser_df(df_tpermno_dw_dw_plus_one, \n",
    "                                          get_stock_vol_from_ser_CRSP, \n",
    "                                          return_as_df=True, \n",
    "                                          use_new_cols=['vol_dw', 'vol_dw_plus_one'],\n",
    "                                                        db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9c619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011\n"
     ]
    }
   ],
   "source": [
    "# default is `dw`\n",
    "df.dr_corrected[df.statc.eq('W')] = dw\n",
    "# \n",
    "index_dw_to_correct = df_w.index[volumes_dw_df.vol_dw_plus_one.gt(volumes_dw_df.vol_dw, fill_value=0)]\n",
    "print(len(index_dw_to_correct))\n",
    "df.dr_corrected[index_dw_to_correct] = dw_plus_one_day[index_dw_to_correct]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9b067",
   "metadata": {},
   "source": [
    "# create `duration`\n",
    "Duration is the number of trading days between `da_corrected` and `dr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19dd53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk.insert_cols(df, 'definitive_agt', 'duration', dsk.get_num_trading_days_between(df.da_corrected, df.dr_corrected))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a31e6f",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9bdbd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = f\"{path}/data/dates_corrected.h5\"\n",
    "df[['one_day', 'da_corrected', 'dr', 'duration']].to_hdf(filepath, key='dates', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4e209d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = f\"{path}/data/df_dates_corrected.h5\"\n",
    "df.to_hdf(filepath, key='df', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
